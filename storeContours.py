from functions import find, store_rtss_as_structureinstance, getKey, store_arrays_hdf5
import pydicom
import os
import numpy as np
import pandas as pd
from compress_pickle import dump, load
from datetime import datetime


HDF5_DIR = "H:\\Treatment Planning\\Elguindi\\storage"
masterStructureList = "G:\\Projects\\mimTemplates\\StructureListMaster.xlsx"
contourDatabase = "H:\\Treatment Planning\\Elguindi\\contourDatabase\\contourDB.xlsx"

structureTypes = ['autoGenerated', 'mimLatest', 'physicianApproved', 'eclipseLatest',
                  'APL', 'TP volume', 'FN volume', 'FP volume', 'SEN', '%FP',
                  '3D DSC', '2D HD', '95% 2D HD', 'Ave 2D Dist', 'Median 2D Dist',
                  'Reference Centroid', 'Test Centroid', 'SDSC_1mm', 'SDSC_3mm', 'RobustHD_95', 'ref_vol', 'test_vol']

structureList = pd.read_excel(masterStructureList)
sl = [x.upper() for x in structureList['StructureName'].to_list()]
sl_alt = [str(x).upper() for x in structureList['TG263_Equivalent'].to_list()]

columns = ['MRN', 'SCAN_FILE', 'SCAN_DATE']
for struct in sl:
    for structureType in structureTypes:
        columns.append(struct + '_' + structureType)


triggerFiles = find('*.trigger', 'S:\\AutoSeg\\ForAnalysis\\')


if not os.path.isfile(contourDatabase):
    db = pd.DataFrame(columns=columns, dtype='str')
else:
    print('Database Exists, adding patient study: ' + contourDatabase)
    db = pd.read_excel(contourDatabase, index=False)

for column in columns:
    if column not in db:
        db[column] = ""
    else:
        db[column] = db[column].astype('str')

for triggerFile in triggerFiles:
    dirList = os.listdir(triggerFile.strip('.trigger'))
    for directory in dirList:
        if 'CT' in directory[0:2]:
            dcmFiles = find('*.dcm', os.path.join(triggerFile.strip('.trigger'), directory))
            print(directory)
            if dcmFiles:
                arrayTuple = []
                for dcmFile in dcmFiles:
                    dataset = pydicom.dcmread(dcmFile)
                    pixelSpacing = dataset.PixelSpacing
                    pixelSpacing.append(dataset.SliceThickness)
                    ImagePosition = dataset.ImagePositionPatient
                    ImagePosition.append(1)
                    X = dataset.ImageOrientationPatient[0:3]
                    Y = dataset.ImageOrientationPatient[3:]
                    coordinateSystemTransform = np.zeros((4, 4))
                    coordinateSystemTransform[0:3, 0] = np.asarray(X) * np.asarray(pixelSpacing[0])
                    coordinateSystemTransform[0:3, 1] = np.asarray(Y) * np.asarray(pixelSpacing[1])
                    coordinateSystemTransform[0:, 3] = ImagePosition
                    arrayTuple.append([np.float(dataset.SliceLocation), dataset.pixel_array, coordinateSystemTransform])

                arrayTuple = sorted(arrayTuple, key=getKey)
                data = {}
                sliceLocations = np.zeros((len(arrayTuple)))
                imageSize = np.asarray([len(arrayTuple), dataset.Rows, dataset.Columns, 1])
                pixelConversion = np.asarray([dataset.RescaleIntercept, dataset.RescaleSlope])
                pixelData = np.zeros(imageSize)
                coordinateTransforms = np.zeros((4, 4, len(arrayTuple)))

                l = 0
                for sliceLocation, image, coordinateSystemTransform in arrayTuple:
                    coordinateTransforms[:, :, l] = coordinateSystemTransform
                    sliceLocations[l] = sliceLocation
                    pixelData[l, :, :, 0] = image
                    l = l + 1
                data['sliceLocations'] = sliceLocations
                data['imageSize'] = imageSize
                data['pixelConversion'] = pixelConversion
                data['imageMatrix'] = pixelData
                data['coordinateSystemTransform'] = coordinateTransforms
                date_obj = datetime.strptime(dataset.StudyDate + dataset.StudyTime[0:5], '%Y%m%d%H%M%S')
                filename = dataset.StudyInstanceUID
                file = os.path.join(HDF5_DIR, filename + '.h5')
                if not (db['MRN'] == dataset.PatientID).any():
                    db = db.append({'MRN': dataset.PatientID}, ignore_index=True)
                else:
                    print('Patient is in database')
                if not os.path.isfile(file):
                    store_arrays_hdf5(data, HDF5_DIR, filename)
                    if not (db['SCAN_FILE'] == filename + '.h5').any():
                        db.at[db.index[db['MRN'] == dataset.PatientID].tolist()[0], 'SCAN_FILE'] = filename + '.h5'
                        db.at[db.index[db['MRN'] == dataset.PatientID].tolist()[0], 'SCAN_DATE'] = date_obj.strftime('%Y-%m-%d %H:%M:%S')
                    else:
                        print('Series already in database')
                else:
                    print('Same Image Series UID Exists: ' + filename)

        elif 'RTSTRUCT' in directory.upper() and 'ATLAS' in directory.upper():

            dcmFiles = find('*.dcm', os.path.join(triggerFile.strip('.trigger'), directory))
            print(directory)
            if len(dcmFiles) == 1:
                dataset = pydicom.dcmread(dcmFiles[0])
                timeStamp = dataset.StructureSetDate + '-' + dataset.StructureSetTime.replace('.', '-')
                if not (db['MRN'] == dataset.PatientID).any():
                    db = db.append({'MRN': dataset.PatientID}, ignore_index=True)
                structureData, structureMatches = store_rtss_as_structureinstance(dcmFiles[0], sl, sl_alt,
                                                                                  as_polygon=False)
                for structure in structureData:
                    filename = structure[0] + '-' + timeStamp + '.gz'
                    dump(structure[1], open(os.path.join(HDF5_DIR, filename), 'wb'), compression='gzip')
                    column_name = structure[0].upper() + '_' + structureTypes[0]
                    if not (db[column_name] == filename).any():
                        db.at[db.index[db['MRN'] == dataset.PatientID].tolist()[0], column_name] = filename
                    else:
                        print('Structure Already in Database:' + structure[0])
            else:
                print('Multiple RTSTRUCT files labled the same in directory: ' + directory)
            print('...')
            print('Row updated for patient directory: ' + directory)
            db.to_excel(contourDatabase, index=False)

        elif 'RTSTRUCT' in directory.upper() and 'SENT' in directory.upper():

            dcmFiles = find('*.dcm', os.path.join(triggerFile.strip('.trigger'), directory))
            print(directory)
            if len(dcmFiles) == 1:
                dataset = pydicom.dcmread(dcmFiles[0])
                timeStamp = dataset.StructureSetDate + '-' + dataset.StructureSetTime.replace('.', '-')
                if not (db['MRN'] == dataset.PatientID).any():
                    db = db.append({'MRN': dataset.PatientID}, ignore_index=True)
                structureData, structureMatches = store_rtss_as_structureinstance(dcmFiles[0], sl, sl_alt,
                                                                                  as_polygon=False)
                for structure in structureData:
                    filename = structure[0] + '-' + timeStamp + '.gz'
                    dump(structure[1], open(os.path.join(HDF5_DIR, filename), 'wb'), compression='gzip')
                    column_name = structure[0].upper() + '_' + structureTypes[1]
                    if not (db[column_name] == filename).any():
                        db.at[db.index[db['MRN'] == dataset.PatientID].tolist()[0], column_name] = filename
                    else:
                        print('Structure Already in Database:' + structure[0])
            else:
                print('Multiple RTSTRUCT files labled the same in directory: ' + directory)
            print('...')
            print('Row updated for patient directory: ' + directory)
            db.to_excel(contourDatabase, index=False)





